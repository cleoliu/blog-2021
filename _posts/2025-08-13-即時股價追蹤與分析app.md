---
layout: post
title: "即時股價追蹤與分析App"
date: 2025-08-13 09:56:19 +0800
categories: []
tags: []
description: "即時股價追蹤與分析App"
image: https://res.cloudinary.com/dsvl326mi/image/upload/v1755050178/blog_covers/IMG_2178_gbna3h.jpg

---

好的，這是一篇將 AI 對話內容（關於 403 Forbidden 錯誤）轉換為完整教學文章的 Markdown 格式內容，並遵循您指定的所有要求：

---
```yaml
---
title: 解決網頁內容抓取中的403 Forbidden錯誤
date: 2025-08-13 10:46:57 +0800
categories:
  - Web Scraping
  - Python
  - Error Handling
tags:
  - HTTP 403
  - Forbidden
  - requests library
  - User-Agent
  - Web Scraping
  - Python
description: 本文將指導您如何在使用Python的requests庫進行網頁內容抓取時，解決常見的HTTP 403 Forbidden錯誤，並提供實用的程式碼範例與錯誤處理策略。
---
```text
## 導言

在進行網頁內容抓取（Web Scraping）時，我們經常會遇到各種 HTTP 狀態碼。其中，`403 Forbidden` 錯誤是一個非常普遍且令人沮喪的問題。當您嘗試使用程式碼（例如 Python 的 `requests` 函式庫）訪問一個網址時，如果遇到 `403 Forbidden` 錯誤，這表示伺服器理解您的請求，但拒絕執行它。這通常是為了保護網站資源，防止惡意爬蟲或未經授權的訪問。

本文的目標是深入探討 `403 Forbidden` 錯誤的常見原因，並提供使用 Python `requests` 函式庫解決這些問題的實用方法和程式碼範例。您將學會如何模擬瀏覽器行為，以及如何處理其他可能導致抓取失敗的相關問題。

## 前置需求

在開始實作之前，請確保您的環境符合以下要求：

*   **Python 3.x 環境**：建議使用最新穩定版本的 Python。
*   **`requests` 函式庫**：這是 Python 中用於發送 HTTP 請求的標準函式庫。如果尚未安裝，請使用 pip 進行安裝：

    ```bash
    pip install requests
    ```text
## 實作步驟

本節將帶您逐步了解如何診斷並解決 `403 Forbidden` 錯誤。

### 步驟 1：模擬錯誤情境

首先，讓我們模擬一個可能導致 `403 Forbidden` 錯誤的請求。許多網站會檢查請求的 `User-Agent` 標頭。如果缺少此標頭，或者其值不被伺服器接受，伺服器就可能返回 `403`。

```python
import requests

# 替換為您可能遇到403錯誤的目標網址
# 注意：以下網址僅為範例，實際操作請勿對他人網站進行惡意爬取或造成負擔。
# 某些網站即使沒有User-Agent也不會立即返回403，您可能需要測試不同的目標。
target_url = "https://www.example.com/protected_resource"

try:
    response = requests.get(target_url)
    response.raise_for_status() # 這會在狀態碼不是200時拋出HTTPError
    print(f"成功獲取內容，狀態碼: {response.status_code}")
    print("部分內容預覽:")
    print(response.text[:500]) # 打印前500個字符作為預覽
except requests.exceptions.HTTPError as e:
    print(f"錯誤：無法獲取網址內容：{e}")
    print(f"錯誤狀態碼: {e.response.status_code}")
    print(f"請求的 URL: {e.response.url}")
    print("這通常表示遇到了 4xx 或 5xx 錯誤。")
except requests.exceptions.RequestException as e:
    print(f"請求發生其他錯誤: {e}")
    print("這可能是一個連線錯誤、超時等問題。")

```text
運行上述程式碼，如果目標網站有防爬機制，您很可能會看到類似 `錯誤：無法獲取網址內容：403 Client Error: Forbidden for url: [您的網址]` 的輸出。

### 步驟 2：理解 403 Forbidden 錯誤的原因

當您收到 `403 Forbidden` 錯誤時，這意味著伺服器拒絕了您的請求，常見原因包括：

1.  **缺少或不合適的 `User-Agent` 標頭**：這是最常見的原因。許多網站會檢查 `User-Agent` 標頭來判斷請求是否來自一個標準瀏覽器。如果沒有這個標頭，或者它看起來像自動化程式，伺服器可能會拒絕服務。
2.  **IP 位址限制**：網站可能限制來自特定 IP 範圍的訪問，或檢測到來自單一 IP 的大量請求，從而暫時或永久封鎖該 IP。
3.  **缺少 `Referer` 標頭**：某些網站會檢查 `Referer` 標頭，以確保請求是從其預期的來源頁面發起的。
4.  **Cookie 或 Session 問題**：如果網站需要登入或特定的會話狀態，而您的請求沒有包含必要的 Cookie，也可能導致 `403`。
5.  **地理位置限制**：網站可能限制某些國家或地區的訪問。
6.  **機器人檢測 (CAPTCHA)**：在某些情況下，網站會要求通過 CAPTCHA 驗證，而自動化程式無法直接處理。

### 步驟 3：添加 `User-Agent` 標頭解決問題

最常見的解決方案是將 `User-Agent` 標頭添加到您的請求中，使其看起來像一個真正的瀏覽器。您可以透過在瀏覽器中開啟開發者工具（通常按 `F12`），然後在「Network」（網路）標籤下查看任何請求的「Request Headers」（請求標頭）來獲取一個有效的 `User-Agent` 字串。

```python
import requests

target_url = "https://www.example.com/protected_resource" # 替換為您的目標網址

# 定義一個常見的瀏覽器 User-Agent
# 您可以在瀏覽器開發者工具中獲取最新的 User-Agent
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

try:
    response = requests.get(target_url, headers=headers)
    response.raise_for_status() # 檢查HTTP狀態碼
    print(f"成功獲取內容，狀態碼: {response.status_code}")
    print("部分內容預覽:")
    print(response.text[:500])
except requests.exceptions.HTTPError as e:
    print(f"錯誤：無法獲取網址內容：{e}")
    print(f"錯誤狀態碼: {e.response.status_code}")
    print(f"請求的 URL: {e.response.url}")
except requests.exceptions.RequestException as e:
    print(f"請求發生其他錯誤: {e}")

```text
透過添加 `User-Agent`，許多網站會將您的請求視為合法的瀏覽器訪問，從而允許您獲取內容。

### 步驟 4：添加更多請求標頭以提高成功率

某些網站可能不僅檢查 `User-Agent`，還會檢查其他 HTTP 標頭來判斷請求的合法性。為了更完整地模擬瀏覽器行為，您可以添加更多常見的標頭，例如 `Accept`、`Accept-Language`、`Accept-Encoding` 等。

```python
import requests

target_url = "https://www.example.com/protected_resource" # 替換為您的目標網址

# 定義更完整的請求標頭
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
    "Accept-Language": "en-US,en;q=0.5",
    "Accept-Encoding": "gzip, deflate, br",
    "DNT": "1", # Do Not Track request header
    "Connection": "keep-alive",
    "Upgrade-Insecure-Requests": "1",
    # Referer - https -//www.google.com/ # 如果需要，可以添加來源頁面
    # Cookie - your_cookie_string_here # 如果需要登入或特定會話，請在此處添加
}

try:
    response = requests.get(target_url, headers=headers)
    response.raise_for_status()
    print(f"成功獲取內容，狀態碼: {response.status_code}")
    print("部分內容預覽:")
    print(response.text[:500])
except requests.exceptions.HTTPError as e:
    print(f"錯誤：無法獲取網址內容：{e}")
    print(f"錯誤狀態碼: {e.response.status_code}")
    print(f"請求的 URL: {e.response.url}")
except requests.exceptions.RequestException as e:
    print(f"請求發生其他錯誤: {e}")

```text
### 步驟 5：處理重定向

有時候，即使請求成功，網站也可能將您重定向到另一個頁面（例如登入頁面或錯誤頁面），這可能不是您期望的內容。`requests` 函式庫預設會自動處理重定向，但您可以使用 `response.history` 來查看重定向歷史，或設定 `allow_redirects=False` 來禁用自動重定向。

```python
import requests

target_url = "https://www.example.com/old_page" # 可能會重定向的網址

try:
    response = requests.get(target_url, allow_redirects=True) # 預設就是True
    print(f"最終 URL: {response.url}")
    if response.history:
        print("重定向歷史:")
        for resp in response.history:
            print(f"  {resp.status_code} {resp.url}")
    response.raise_for_status()
    print(f"成功獲取內容，狀態碼: {response.status_code}")
except requests.exceptions.RequestException as e:
    print(f"請求發生錯誤: {e}")

```text
## 常見錯誤與解法

除了 `403 Forbidden` 之外，您在網頁抓取過程中還可能遇到其他常見問題：

*   **`403 Forbidden`**：
    *   **解法**：如上所述，添加 `User-Agent` 和其他相關標頭 (如 `Referer`, `Cookie`)。嘗試使用不同的 `User-Agent` 字串。
    *   **進階解法**：使用代理伺服器（Proxy）切換 IP 地址；使用 `requests.Session()` 管理 Cookie 和會話；如果網站有 JavaScript 動態內容或 CAPTCHA，可能需要使用 `Selenium` 或 `Playwright` 等無頭瀏覽器工具。

*   **`404 Not Found`**：
    *   **問題**：請求的資源在伺服器上不存在。
    *   **解法**：仔細檢查您請求的 URL 是否正確，包括大小寫和路徑。

*   **`429 Too Many Requests`**：
    *   **問題**：您在短時間內發送了太多請求，伺服器限制了您的訪問。
    *   **解法**：在請求之間加入延遲（例如使用 `time.sleep()`），遵守網站的 `robots.txt` 協定，不要對網站造成過大負擔。

*   **`5xx Server Error`** (例如 `500 Internal Server Error`, `503 Service Unavailable`)：
    *   **問題**：伺服器端發生錯誤。
    *   **解法**：這通常不是您程式碼的問題。可以嘗試稍後重試，或者檢查網站的服務狀態。

*   **`requests.exceptions.ConnectionError`**：
    *   **問題**：無法建立與伺服器的連接，可能由於網路問題、DNS 解析失敗、防火牆設置或目標伺服器離線。
    *   **解法**：檢查您的網路連接，確認目標 URL 是否可訪問，或檢查您的防火牆設置。

*   **`requests.exceptions.SSLError`**：
    *   **問題**：SSL/TLS 憑證驗證失敗。
    *   **解法**：確保您的系統時間是準確的。對於測試用途，您可以設置 `verify=False` 來禁用 SSL 證書驗證，但**這在生產環境中非常不安全**，會讓您的連接容易受到中間人攻擊。

*   **網站內容由 JavaScript 動態生成**：
    *   **問題**：`requests` 函式庫只能獲取初始 HTML 內容，無法執行 JavaScript。如果網站內容在瀏覽器載入後才透過 JavaScript 渲染，`requests` 將無法獲取這些內容。
    *   **解法**：使用無頭瀏覽器工具，如 `Selenium` 或 `Playwright`，它們可以模擬真實瀏覽器執行 JavaScript 並獲取最終渲染後的頁面內容。

## 延伸應用與學習資源

了解如何處理 `403` 錯誤只是網頁抓取的冰山一角。以下是一些可以進一步學習和應用的方向：

*   **處理 Cookies 和 Sessions**：
    *   使用 `requests.Session()` 物件來持久化請求之間的 Cookie，這對於需要登入或保持會話狀態的網站非常有用。
*   **使用代理伺服器 (Proxies)**：
    *   當您的 IP 被封鎖或需要隱藏 IP 地址時，可以使用代理伺服器。
    *   ```python
        proxies = {
            "http": "http://user:pass@10.10.1.10:3128",
            "https": "http://user:pass@10.10.1.10:1080",
        }
        response = requests.get(url, headers=headers, proxies=proxies)
        ```text
*   **解析 HTML 內容**：
    *   `requests` 函式庫只負責獲取網頁內容，您還需要工具來解析這些 HTML，提取所需數據。`BeautifulSoup4` 是最常用和方便的 HTML 解析庫。
    *   ```bash
        pip install beautifulsoup4 lxml
        ```text
    *   ```python
        from bs4 import BeautifulSoup
        # ... (response獲取代碼)
        soup = BeautifulSoup(response.text, 'lxml')
        # 然後可以使用soup對象查找元素
        # 例如：title = soup.find(title).text
        ```text
*   **處理動態內容 (JavaScript)**：
    *   當 `requests` 無法獲取動態內容時，考慮使用 `Selenium` 或 `Playwright`。
    *   **Selenium**: 通常需要一個瀏覽器驅動（如 ChromeDriver），可以模擬用戶點擊、滾動等操作。
    *   **Playwright**: 支援多種瀏覽器引擎，提供更現代的異步 API。
*   **遵守網站的 `robots.txt` 協定**：
    *   在抓取任何網站之前，檢查其 `robots.txt` 文件 (`網站域名/robots.txt`)，了解哪些頁面是允許或不允許抓取的。這是負責任的網頁抓取行為。
*   **增加請求間的延遲**：
    *   為了避免對網站造成過大的負載，並減少被檢測為爬蟲的風險，請在連續請求之間加入適當的延遲 (`import time; time.sleep(秒數)`)。

**推薦學習資源**：

*   **Requests 官方文檔**：[https://docs.python-requests.org/en/latest/](https://docs.python-requests.org/en/latest/)
*   **BeautifulSoup 官方文檔**：[https://www.crummy.com/software/BeautifulSoup/bs4/doc/](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)
*   **Selenium 官方文檔**：[https://www.selenium.dev/documentation/en/](https://www.selenium.dev/documentation/en/)
*   **Playwright 官方文檔**：[https://playwright.dev/python/](https://playwright.dev/python/)

希望這篇文章能幫助您有效解決在網頁內容抓取中遇到的 `403 Forbidden` 錯誤及其他相關問題！