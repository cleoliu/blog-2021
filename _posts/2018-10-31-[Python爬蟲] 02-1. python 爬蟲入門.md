---
layout: post
title: "[Python爬蟲] 02-1. python 爬蟲入門"
categories: [Python爬蟲]
tags: [實做, Python, 爬蟲]
description: 爬蟲可以減少一些人工上的麻煩事，在大量或是經常性的工作，自動化便是一個重要的議題。簡單來說就是把網頁內容給拿回來，接著透過程式去篩選出有意義的資訊！...
---

> 爬蟲可以減少一些人工上的麻煩事，在大量或是經常性的工作，自動化便是一個重要的議題。簡單來說就是把網頁內容給拿回來，接著透過程式去篩選出有意義的資訊！關於 python 爬蟲有幾種方式，第一種是 `Selenium` **模擬瀏覽器的操作**，查看 HTML 網頁原始碼，獲得頁面元素，可適用於動態網頁。第二種是使用 `requests` **Api get/post 發送請求** 並接收回應。若是只採用這兩種方法會建議以 requests 優先使用，因 Api 在程式開發過程中較 HTML 不會更改，在維護我們的爬蟲程式上較為方便。再來說說 `Scrapy`，它是個爬蟲的框架，支援爬蟲所需要的大部分東西，包含了 requests 的範圍，程式較 requests 好寫，但由於是框架所以不夠彈性，在對於大型爬蟲，並行及分布式處理不夠靈活，scrapy 中 scheduler 是運行在隊列中的，而隊列是在單機內存中的，伺服器上爬蟲是無法利用內存的隊列做任何處理。

<br/>

## 具備技能：
- Selenium 元素操作
- HTTP 協定知識： [01. Http 協定](http://cleoblog.ml/network/2018/10/16/Network-01.-Http-%E5%8D%94%E5%AE%9A.html)

<br/>

## 主題大綱
詳細介紹請參考以下：
1. [HTML 跟 CSS 基礎](http://cleoblog.ml/python爬蟲/2018/11/01/Python爬蟲-02-2.-HTML-跟-CSS-基礎.html)
2. [Http 協定](http://cleoblog.ml/network/2018/10/16/Network-01.-Http-協定.html)
3. [requests](http://cleoblog.ml/python爬蟲/2018/11/02/Python爬蟲-02-3.-requests-HTTP-GET&POST.html)
4. [Selenium](http://cleoblog.ml/python爬蟲/2018/11/03/Python爬蟲-02-4.-Selenium-瀏覽器模擬.html)
5. [BeautifulSoup](http://cleoblog.ml/network/2018/11/03/Python爬蟲-02-5.-BeautifulSoup-解析-HTML-程式碼.html)
6. [防爬蟲機制](http://cleoblog.ml/network/2018/11/05/Python爬蟲-02-6.-破解幾種防爬蟲機制.html)
8. [多執行續爬蟲](http://cleoblog.ml/network/2018/11/06/Python爬蟲-03-多執行緒.html)
7. [非同步爬蟲](http://cleoblog.ml/network/2018/11/07/Python爬蟲-02-7.-async-和-await-非同步爬蟲.html)

<br/>

***

## win7 開發環境

> requests 和 Selenium 為主動方，用來執行觸發操作，BeautifulSoup 則是在得到結果之後在進行數據的整理。

- Python 3
- `requests`：對目標網頁的 server 發出 HTTP requests，底層是 urllib。

    ```bash
    $ pip3 install requests
    ```

- `Selenium`：模擬瀏覽器執行。

    ```bash
    $ pip3 install Selenium
    ```

- `BeautifulSoup`：HTML 解析工具，解構並擷取網頁資訊。

    ```bash
    $ easy_install pip
    $ pip install BeautifulSoup4
    ```

<br/>

***

## 觀察工具

- `Chrome Developer Tool`
    - 觀察 html / css
- `Network` tab 觀察 api 動作
    - request 順序
    - url
    - method
    - post data、query data
    - header

<br/>

## 測試工具

- `Postman` 模擬傳送 api request
    - get/post
    - method
    - Url
    - header
    - data(query params or post data)

<br/>

## 爬蟲原則

- 每個 request 應該將它當成是單一事件。
- 注意 header 裡的資訊。
- 如使用者帳號密碼的驗證，資訊存在 session 裡面，在 client 使用 cookie 存放 session ID。

<br/>

***

## 程式範例 [1](https://pala.tw/python-web-crawler/)

- `selenium` 爬取網頁結果。
    ```python
    from selenium import webdriver
    from bs4 import BeautifulSoup
    
    url = 'https://www.google.com.tw/#q=%E8%9F%B2%E5%B8%AB'
    
    driver = webdriver.PhantomJS(executable_path=r'請輸入路徑')  #PhantomJS
    driver.get(url)  #把網址交給瀏覽器 
    pageSource = driver.page_source  #取得網頁原始碼
    soup = BeautifulSoup(pageSource, 'lxml')  #解析器接手
    result = soup.select('#resultStats')[0].get_text()  #「約有1,550,000,000項結果」
    print('蟲師', result)
    ```

- `selenium` 捲動瀑布流網頁，捲動的寫法。
    ```python
    import time
    from selenium import webdriver
    from bs4 import BeautifulSoup
    
    driver = webdriver.Chrome(executable_path=r'請輸入路徑') #chrome瀏覽器
    time.sleep(3)
    driver.get('https://hahow.in/courses')
    
    for i in range(10):  #進行十次
        driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')  #重複往下捲動
        time.sleep(1)  #每次執行打瞌睡一秒                    
    
    driver.close()  #關閉瀏覽器
    ```

- `selenium` 全螢幕截圖。
    ```python
    from selenium import webdriver
    
    driver = webdriver.Chrome(executable_path=r'請輸入路徑')
    driver.get('http://www.pixiv.net/')
    driver.save_screenshot('儲存位置/檔案名稱.png')  #保存截圖
    driver.close()
    ```

- `requests` 爬取驗證碼圖片。
    ```python
    import requests
    from PIL import Image
    import io

    getCode_url = "http://99.xxxxxxxxx.com/seccode.php?update=0.6444653254985074"
    header = {
        "Referer":"http://99.xxxxxxxxx.com/?bmwid=1",
        "Cookie":"PHPSESSID=f6ugbha1lofph397uca9rvqjd2"
    }
                
    response = requests.get(getCode_url,headers=header).content
    image = Image.open(io.BytesIO(response))
    print("獲取驗證碼成功")
    image.show()
    image.save("test.png","png")
    ```

<br/>

***

## ref：

- [技能樹](https://kknews.cc/other/pe5b868.html)
- [網路爬蟲Day1 - 概述](https://ithelp.ithome.com.tw/articles/10190994)
- [【爬蟲】從Dcard網站看爬蟲入門](https://medium.com/pyladies-taiwan/%E5%BE%9Edcard%E7%B6%B2%E7%AB%99%E7%9C%8B%E7%88%AC%E8%9F%B2%E5%85%A5%E9%96%80-65105f0ddac)
- [Python 使用 requests 模組產生 HTTP 請求 ](https://blog.gtwang.org/programming/python-requests-module-tutorial/)
- [JB的Python之旅-爬蟲篇-圖形驗證碼(3)-- 驗證碼的生成了解下](https://tw.saowen.com/a/4895a66f2c3357fe5d67ee39ea3fc14fb697a51093343785056c326c4123b709)

<br/><br/>
