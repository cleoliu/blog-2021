---
layout: post
title: "[Python爬蟲] 06. 幾種防爬蟲機制"
categories: [爬蟲]
tags: [爬蟲]
featured-img: emile-perron-190221
---



## 常見的幾種反爬蟲機制 [1](https://ithelp.ithome.com.tw/articles/10191165)

> 網站的防爬蟲機制，一般都是在 requests 的階段會碰到問題。

<br>

### 常見防爬蟲機制

- **網站使用識別技術**：網站登入使用驗證碼，可參考此文 [01. pytesseract 驗證碼自動識別](http://cleoblog.ml/python/2018/10/26/Python-01.-pytesseract-%E9%A9%97%E8%AD%89%E7%A2%BC%E8%87%AA%E5%8B%95%E8%AD%98%E5%88%A5.html)。
- **JavaScript**：收到的頁面是空白的，有可能是因為網站頁面的 JavaScript 執行有問題。
- **瀏覽器 requests 的參數**：提交表單或發出 POST 請求，記得檢查一下頁面的內容，看看你想提交的每個欄位是不是都已經填好，而且格式也正確。
- **要求 Cookie**：確認在加載每個頁面時 cookie 都被正確調用，要在一個網站上持續保持登錄狀態，需要在多個頁面中保存一個 cookie。有些網站不要求在每次登錄時都獲得一個新 cookie，只要保存一個舊的「已登錄」的 cookie 就可以訪問。（可使用 Chrome 插件 [EditThisCookie](https://chrome.google.com/webstore/detail/editthiscookie/fngmhnnpilhplaeedifhccceomclgfbg)）
- **IP 被封禁**：HTTP 錯誤，如 403 禁止訪問錯誤，這可能說明網站已經把你的 IP 當作機器人了，不再接受你的任何請求。方法是等待你的 IP 地址從網站黑名單里移除，或換個 IP 地址
    - **爬蟲頻繁的發送請求**：會對網管的伺服器造成沉重的負擔，也是 IP 被網站列入黑名單的首要原因。
        - 增加延遲時間
        - 可變的遠程 IP 地址
        - Tor 代理伺服器
        - 從雲主機運行
    - **requests header**：有些網站會封殺任何聲稱自己是爬蟲的訪問者。
- **動態頁面的反爬蟲**：需要爬取的數據是通過 ajax 請求得到，或者通過 JavaScript 生成的，可使用 selenium+phantomJS 來運行

<br>

***

## 構造合理的 HTTP requests header

- 伺服器端偵測到的可能就是 Python 用戶端送出的 requests，有些防爬蟲比較高階的網站會檔下這類型的 requests。
- 可以透過 F12>Network>目標頁面>Requests Headers 找到。User-Agent 為必填欄位：

    ```python
    import requests

    #這是一個很有名的，爬蟲愛好者常去挑戰的一個募資網站
    url = "https://www.indiegogo.com/projects/viviva-colorsheets-the-most-portable-watercolors-painting-travel--4#/" 
    
    #使用假header
    headers = {'user-agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/52.0.2743.116 Safari/537.36'}
    re = requests.get(url, headers=headers) 
    re.encoding = 'utf8'
    print(re.text)
    ```

<br>

***

## 爬蟲頻繁的發送請求

### 增加延遲時間
- 可以使用 time 這個套件，讓程式休息一些時間。

    ```python
    import time
    time.sleep(2)   #休息2秒
    ```

### Tor 代理伺服器

> SOCKS 代理和 HTTP 代理有什麼不同？在 OSI 七層模型中，SOCKS 工作在會話層上，而 HTTP 工作在應用層上，SOCKS 代理只是簡單地傳遞數據包，而不必關心是何種應用協議（比如 FTP、HTTP 和 NNTP 請求），所以 SOCKS 代理服務器比應用層代理服務器要快得多。

#### 安裝

- `Tor`：是一種 IP 地址匿名手段。

    ```bash
    $ brew install tor
    ```

- `PySocks`： Python 代理伺服器通信模塊。

    ```bash
    $ pip install PySocks
    ```

- `requests`

    ```bash
    $ pip install requests
    ```

<br>

#### 使用 Tor

- 命令行啟動 tor , tor 預設 port 號 9050。

    ```bash
    $ tor  #啟動
    ```

- python

    ```python
    import socks 
    import requests 
    import socket  
    
    #所有的請求都走tor 
    socks.set_default_proxy(proxy_type=socks.SOCKS5, addr="127.0.0.1", port=9050) 
    socket.socket = socks.socksocket  
    print(requests.get("http://icanhazip.com").text)

    >>>
    163.172.142.15
    ```

- tor 預設每隔 10 分鐘左右更換一次 IP 地址，也可以強制更換，更新方法：

    ```python
    import os
    os.system("killall -HUP tor")
    ```

- 關閉 tor。

    ```bash
    $ killall tor
    ```

- 在 Tor 裡面用 Selenium 和 PhantomJS，不需要 PySocks，只要保證 Tor 在運行，然後增加 service_args 參數設置代理埠，讓 Selenium 通過埠 9050 連接網站就可以了。

<br>

***

## 動態網頁 javascript 渲染出來的網頁

- 動態網頁若使用 requests JavaScript 則不會顯示出來，對應方式可使用 Selenium。
- 對任何元素做動作的時候，最好要設定保護機制，如果元素還沒出來，將無法定位到元素，後面的操作也不會成功，可使用 try/except 機制。
- 可使用 PhantomJs 瀏覽器，PhantomJs 會在背景後執行，消耗較少資源，直接呈現結果。

    ```python
    from selenium import webdriver
    
    driver = webdriver.PhantomJS(executable_path=r'請輸入路徑')  #PhantomJs
    driver.get('http://pala.tw/js-example/')                    #輸入範例網址，交給瀏覽器 
    pageSource = driver.page_source                             #取得網頁原始碼
    print(pageSource)
    
    driver.close()  #關閉瀏覽器
    ```

<br>

***

## ref：
- [為何大量網站不能抓取?爬蟲突破封禁的6種常見方法](https://kknews.cc/zh-tw/tech/mjqmg.html)
- [常見的反爬蟲和應對方法](https://zhuanlan.zhihu.com/p/20520370)

<br><br>